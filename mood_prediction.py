# -*- coding: utf-8 -*-
"""Mood_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kZzGh8yZzChJLaGrnjqlyHXDBDpRBDf_
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
data=pd.read_csv('/content/drive/My Drive/fer2013.csv')
#Preprocessing the data
train_set = data[(data[' Usage'] == 'Training')]
validation_set = data[(data[' Usage']== 'PublicTest')]
test_set = data[(data[' Usage'] == 'PrivateTest')]

emotion_labels=["Angry","Disgust","Fear","Happy","Sad","Surprise","Neutral"]
num_classes=len(emotion_labels)

from math import sqrt
depth = 1
height = int(sqrt(len(data[' pixels'][0].split())))
width = height

X_train=[]
for index,row in train_set.iterrows():
    pixels=list(row[' pixels'].split(' '))
    X_train.append(pixels)
    
X_train=np.array(X_train,dtype=np.float32)

X_test=[]
X_validation=[]

for index,row in test_set.iterrows():
    pixels=list(row[' pixels'].split(' '))
    X_test.append(pixels)
    
X_test=np.array(X_test,dtype=np.float32)

for index,row in validation_set.iterrows():
    pixels=list(row[' pixels'].split(' '))
    X_validation.append(pixels)
    
X_validation=np.array(X_validation,dtype=np.float32)

num_train=X_train.shape[0]
num_test=X_test.shape[0]
num_validation=X_validation.shape[0]

X_train=X_train.reshape(num_train,width,height,depth)
X_test=X_test.reshape(num_test,width,height,depth)
X_validation=X_validation.reshape(num_validation,width,height,depth)

from keras.utils import np_utils
y_train=train_set['emotion']
y_train=np_utils.to_categorical(y_train,num_classes)

y_test=test_set['emotion']
y_test=np_utils.to_categorical(y_test,num_classes)

y_validation=validation_set['emotion']
y_validation=np_utils.to_categorical(y_validation,num_classes)
#Creation Of CNN Starts here
from keras.layers import Convolution2D,Activation,MaxPooling2D,Dense,BatchNormalization,Dropout,Flatten
from keras.models import Sequential

model=Sequential()

model.add(Convolution2D(64,(3,3),padding="same",input_shape=(48,48,1)))
model.add(Convolution2D(64,(3,3),padding="same"))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding="same"))
model.add(Dropout(0.25))


model.add(Convolution2D(128,(3,3),padding="same"))
model.add(Convolution2D(128,(3,3),padding="same"))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding="same"))
model.add(Dropout(0.25))

model.add(Convolution2D(256,(3,3),padding="same"))
model.add(Convolution2D(256,(3,3),padding="same"))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding="same"))
model.add(Dropout(0.25))

model.add(Convolution2D(512,(3,3),padding="same"))
model.add(Convolution2D(512,(3,3),padding="same"))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding="same"))
model.add(Dropout(0.25))

model.add(Flatten())


model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(Dropout(0.25))

model.add(Dense(256))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(Dropout(0.25))

model.add(Dense(7))
model.add(Activation("softmax"))

from keras.preprocessing.image import ImageDataGenerator

datagen=ImageDataGenerator(
        featurewise_center=False,
        samplewise_center=False,
        featurewise_std_normalization=False,
        samplewise_std_normalization=False,
        zca_whitening=False,
        rotation_range=0,
        width_shift_range=0,
        height_shift_range=0.0,
        horizontal_flip=True,
        vertical_flip=False)

datagen.fit(X_train)
datagen.fit(X_validation)

batch_size=32
epochs=10

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

train_flow=datagen.flow(X_train,y_train,batch_size=batch_size)
validation_flow=datagen.flow(X_validation,y_validation)

model.fit_generator(train_flow,
                    steps_per_epoch=len(X_train)/batch_size,
                    epochs=25,
                    verbose=1,
                    validation_data=validation_flow,
                    validation_steps=len(X_validation)/batch_size)
#Saving weights and a JSON File
model_json = model.to_json()
with open("./Live Detection/model.json", "w") as json_file:
    json_file.write(model_json)

model.save_weights('./Live Detection/my_model_weights.h5')
model.save('mood_predict.model')